import streamlit as st
import speech_recognition as sr
import tempfile
from langchain_google_genai import ChatGoogleGenerativeAI
from langchain_core.messages import SystemMessage, HumanMessage, AIMessage
from gtts import gTTS
from dotenv import load_dotenv
import os
import hashlib
from io import BytesIO
from langchain_google_genai.chat_models import ChatGoogleGenerativeAIError

load_dotenv()

# LangSmith tracking
LANGCHAIN_PROJECT = "Urdu Bot"
os.environ["LANGCHAIN_PROJECT"] = LANGCHAIN_PROJECT
os.environ["LANGSMITH_TRACING"] = "true"
os.environ["LANGSMITH_ENDPOINT"] = os.getenv("LANGSMITH_ENDPOINT")
os.environ["LANGSMITH_API_KEY"] = os.getenv("LANGSMITH_API_KEY")

google_key = os.getenv("GOOGLE_API_KEY")

def main():
    st.set_page_config(page_title="Urdu Voice Chatbot", layout="wide")
    st.title("ğŸ¤– Urdu Voice Chatbot")
        
    st.sidebar.title('''About this App''')
    st.sidebar.info(f'''This is a Urdu voice chatbot created using Streamlit. It takes in Urdu voice input and responds in Urdu voice''')

    st.sidebar.write("")
    st.sidebar.write("")

    st.sidebar.write("Developed by :blue[Masoom Tariq]")
    
    # Clear chat button in sidebar
    if st.sidebar.button("ğŸ—‘ï¸ Clear Chat History", use_container_width=True):
        st.session_state.clear()
        initialize_state()
        st.rerun()

    initialize_state()

    # Display chat history
    display_chat_history()
    
    st.divider()

    # Audio input section
    st.subheader("ğŸ¤ Ø§Ù¾Ù†ÛŒ Ø¢ÙˆØ§Ø² Ø±ÛŒÚ©Ø§Ø±Úˆ Ú©Ø±ÛŒÚº")
    st.session_state.audio = st.audio_input("Ù¾ÙˆÚ†Ú¾ÛŒÛ’")

    # Flag to prevent reprocessing same audio
    if 'last_audio_hash' not in st.session_state:
        st.session_state.last_audio_hash = None

    if st.session_state.audio:
        # Create hash of audio to detect new recordings
        audio_bytes = st.session_state.audio.read()
        st.session_state.audio.seek(0)  # Reset position for later reading
        current_hash = hashlib.md5(audio_bytes).hexdigest()
        
        # Only process if this is a new audio (different from last one)
        if current_hash != st.session_state.last_audio_hash:
            st.session_state.last_audio_hash = current_hash
            
            try:
                with st.spinner("ğŸ”„ Ø³Ù† Ø±ÛÛ’ ÛÛŒÚº..."):
                    get_text()
                with st.spinner("ğŸ’­ Ø³ÙˆÚ† Ø±ÛÛ’ ÛÛŒÚº..."):
                    generate_response()
                with st.spinner("ğŸµ Ø¢ÙˆØ§Ø² ØªÛŒØ§Ø± Ú©Ø± Ø±ÛÛ’ ÛÛŒÚº..."):
                    play_audio()
                st.success("âœ… Ø¬ÙˆØ§Ø¨ ØªÛŒØ§Ø± ÛÛ’!")
            
            except sr.UnknownValueError:
                st.error("âŒ Ø¢Ù¾ Ú©ÛŒ Ø¢ÙˆØ§Ø² ÙˆØ§Ø¶Ø­ Ù†ÛÛŒÚº ÛÛ’ - Ø¨Ø±Ø§Û Ú©Ø±Ù… Ø¯ÙˆØ¨Ø§Ø±Û Ú©ÙˆØ´Ø´ Ú©Ø±ÛŒÚºÛ”")
            
            except sr.RequestError:
                st.error("âŒ Ù…Ø¹Ø°Ø±ØªØŒ Ø³Ø³Ù¹Ù… Ú©ÛŒ Ø³Ø±ÙˆØ³ Ù…ØµØ±ÙˆÙ ÛÛ’ØŒ Ø¨Ø±Ø§Û Ú©Ø±Ù… Ø¯ÙˆØ¨Ø§Ø±Û Ú©ÙˆØ´Ø´ Ú©Ø±ÛŒÚºÛ”")
            
            except ChatGoogleGenerativeAIError as e:
                st.error("âŒ Ù…Ø¹Ø°Ø±ØªØŒ AI Ø³Ø±ÙˆØ³ Ù…ÛŒÚº Ø®Ø±Ø§Ø¨ÛŒ ÛÛ’Û” Ø¨Ø±Ø§Û Ú©Ø±Ù… Ø¯ÙˆØ¨Ø§Ø±Û Ú©ÙˆØ´Ø´ Ú©Ø±ÛŒÚºÛ”")
                st.warning("âš ï¸ Ø¨Ø±Ø§Û Ú©Ø±Ù… Ø¨Ø¹Ø¯ Ù…ÛŒÚº Ø¯ÙˆØ¨Ø§Ø±Û Ú©ÙˆØ´Ø´ Ú©Ø±ÛŒÚº")
            
            except Exception as e:
                st.error("âŒ Ø§ÛŒÚ© ØºÛŒØ± Ù…ØªÙˆÙ‚Ø¹ Ø®Ø±Ø§Ø¨ÛŒ ÙˆØ§Ù‚Ø¹ ÛÙˆØ¦ÛŒÛ”")


def display_chat_history():
    """Display formatted chat history with messages"""
    
    # Filter out SystemMessage (only show user and AI messages)
    chat_messages = [msg for msg in st.session_state.history 
                     if not isinstance(msg, SystemMessage)]
    
    if not chat_messages:
        st.info("ğŸ“­ Ú©ÙˆØ¦ÛŒ Ø¨Ú¾ÛŒ Ø¨Ø§Øª Ú†ÛŒØª Ø§Ø¨Ú¾ÛŒ Ø´Ø±ÙˆØ¹ Ù†ÛÛŒÚº ÛÙˆØ¦ÛŒÛ” Ø§Ù¾Ù†Ø§ Ø³ÙˆØ§Ù„ Ù¾ÙˆÚ†Ú¾ÛŒÚº!")
        return
    
    st.subheader("ğŸ’¬ Ø¨Ø§Øª Ú†ÛŒØª Ú©ÛŒ ØªØ§Ø±ÛŒØ®")
    
    # Create a container for chat messages
    chat_container = st.container(border=True)
    
    with chat_container:
        # Display messages in order (oldest to newest)
        for message in chat_messages:
            if isinstance(message, HumanMessage):
                with st.chat_message("user", avatar="ğŸ‘¤"):
                    st.markdown(f"**Ø¢Ù¾:** {message.content}")
            
            elif isinstance(message, AIMessage):
                with st.chat_message("assistant", avatar="ğŸ¤–"):
                    st.markdown(f"**Ø¨ÙˆÙ¹:** {message.content}")
    
    # Show message count
    st.caption(f"ğŸ“Š Ú©Ù„ Ù¾ÛŒØºØ§Ù…Ø§Øª: {len(chat_messages)}")


def initialize_state():
    """Initialize session state variables"""
    initialStates = {
        'text_response': '',
        'history': [],
        'prompt': '',
        'audio': ''
    }
    for key, value in initialStates.items():
        if key not in st.session_state:
            st.session_state[key] = value
    
    if not st.session_state.history:
        instructions = "Ø¢Ù¾ Ø§ÛŒÚ© Ù…Ø¯Ø¯Ú¯Ø§Ø± Ø§Û’ Ø¢Ø¦ÛŒ Ø§Ø³Ø³Ù¹Ù†Ù¹ ÛÛŒÚºÛ” Ø¢Ù¾ ÛØ± ÙˆÛ Ú©Ø§Ù… Ú©Ø± Ø³Ú©ØªÛ’ ÛÛŒÚº Ø¬Ùˆ Ù…Ù†Ø§Ø³Ø¨ ÛÙˆ Ù„ÛŒÚ©Ù† Ø¢Ù¾ ØµØ±Ù Ø§Ø±Ø¯Ùˆ Ø²Ø¨Ø§Ù† Ø¬Ø§Ù†ØªÛ’ ÛÛŒÚº Ø§ÙˆØ± ÛÙ…ÛŒØ´Û ØµØ±Ù Ø§Ø±Ø¯Ùˆ Ø²Ø¨Ø§Ù† Ù…ÛŒÚº Ø¬ÙˆØ§Ø¨ Ø¯ÛŒØªÛ’ ÛÛŒÚºÛ”"
        st.session_state.history.append(SystemMessage(content=instructions))


def get_text():
    """Convert speech to text using Google Speech Recognition"""
    # Audio is already at position 0 from main() seek operation
    with tempfile.NamedTemporaryFile(delete=False, suffix='.wav') as temp_file:
        temp_file.write(st.session_state.audio.read())
        file_path = temp_file.name

    try:
        with sr.AudioFile(file_path) as source:
            r = sr.Recognizer()
            recorded = r.record(source)
            st.session_state.prompt = r.recognize_google(audio_data=recorded, language='ur')
            st.write(f"ğŸ“ **Ø¢Ù¾ Ú©Ø§ Ù¾ÛŒØºØ§Ù…:** {st.session_state.prompt}")
    finally:
        if os.path.exists(file_path):
            os.remove(file_path)


def generate_response():
    """Generate response from LLM using chat history"""
    llm = ChatGoogleGenerativeAI(model="gemini-2.5-flash", temperature=0, api_key=google_key)
    st.session_state.history.append(HumanMessage(content=st.session_state.prompt))
    
    response = llm.invoke(st.session_state.history)
    st.session_state.text_response = response.content
    st.session_state.history.append(AIMessage(content=response.content))
  

def play_audio():
    """Convert text response to speech using gTTS"""
    if not st.session_state.text_response:
        return
        
    ai_audio = gTTS(text=st.session_state.text_response, lang='ur')
    
    # Read audio into bytes instead of saving to file
    audio_buffer = BytesIO()
    ai_audio.write_to_fp(audio_buffer)
    audio_buffer.seek(0)
    
    # Pass bytes directly to st.audio (no file path issues)
    st.audio(audio_buffer, format='audio/mp3')
    st.write(f"ğŸ¤ **Ø¨ÙˆÙ¹ Ú©Ø§ Ø¬ÙˆØ§Ø¨:** {st.session_state.text_response}")


if __name__ == "__main__":
    main()
